{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "int3404.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMsqJLJCzfHVVXDkzcC2jVV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NguyenThuan215/int3404-3-simpleORC/blob/main/int3404.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiYOqDm78ymx"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "import sys\n",
        "import cv2\n",
        "\n",
        "import random\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PP51i6mn9O_y",
        "outputId": "2957eced-f370-419e-be7b-5726e3c7d499"
      },
      "source": [
        "!git clone https://github.com/NguyenThuan215/int3404-3-simpleORC/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'int3404-3-simpleORC'...\n",
            "remote: Enumerating objects: 687, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 687 (delta 4), reused 38 (delta 4), pack-reused 649\u001b[K\n",
            "Receiving objects: 100% (687/687), 654.81 MiB | 18.77 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n",
            "Checking out files: 100% (644/644), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l6CMnuz9Tti"
      },
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     \n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "class HoadonOCR:\n",
        "\n",
        "  def __init__(self):\n",
        "    # Init parameters, load model here\n",
        "    self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    self.modeldir = \"/content/int3404-3-simpleORC/model.pth\"\n",
        "    self.model = self.loadModel(modeldir=self.modeldir, device=self.device)\n",
        "    self.labels = ['highlands', 'others', 'phuclong', 'starbucks']\n",
        "\n",
        "  # TODO: implement find label\n",
        "  def find_label(self, img):\n",
        "    image = self.transformImage(img)\n",
        "    image = image.to(self.device)\n",
        "    self.model.eval()\n",
        "    with torch.no_grad():\n",
        "      output = self.model(image.float())\n",
        "      _, predicted = torch.max(output, dim=1)\n",
        "      print(output, self.labels[int(predicted.cpu().numpy())])\n",
        "\n",
        "    return self.labels[int(predicted.cpu().numpy())]\n",
        "\n",
        "  def loadModel(self, modeldir, device):\n",
        "    model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False)\n",
        "    model.fc = torch.nn.modules.linear.Linear(in_features=512, out_features=4, bias=True)\n",
        "    model.load_state_dict(torch.load(modeldir, map_location=device))\n",
        "    model.to(device)\n",
        "    return model\n",
        "  \n",
        "  def transformImage(self, image):\n",
        "    img_size = 224\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "\n",
        "    img_BGR = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # convert BGR to RGB\n",
        "    img_resize = cv2.resize(img_BGR, (img_size,img_size)) # resize\n",
        "    img_resize = np.array(img_resize, dtype=\"uint8\") # to ndarray\n",
        "    image = img_resize/255 # into 0-1\n",
        "    image_tensor = torch.tensor(image) # convert to tensor\n",
        "    for color in range(3): # nomalize\n",
        "      image_tensor[:,:,color] = (image_tensor[:,:,color] - mean[color])/std[color]\n",
        "\n",
        "    image_tensor = np.transpose(image_tensor, (2, 0, 1)) # transpose\n",
        "    image_tensor = image_tensor.unsqueeze(0) # add dimension\n",
        "    return image_tensor\n",
        "\n",
        "    \n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEq7ul0V9mW2",
        "outputId": "945f1043-c2dd-461e-9f32-7c7db795ed5a"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "  input_folder = '/content/int3404-3-simpleORC/sampledata'\n",
        "  label_file = '/content/int3404-3-simpleORC/labels.csv'\n",
        "\n",
        "  df_labels = pd.read_csv(label_file)\n",
        "  img_name = df_labels['img_name'].values.tolist()\n",
        "  img_labels = df_labels['label'].values.tolist()\n",
        "  img_to_label = dict([(img_name[i], img_labels[i]) for i in range(len(img_name))])\n",
        "\n",
        "  start_time = time.time()\n",
        "  model = HoadonOCR()\n",
        "  init_time = time.time() - start_time\n",
        "  print(\"Run time in: %.2f s\" % init_time)\n",
        "\n",
        "  list_files = os.listdir(input_folder)\n",
        "  print(\"Total test images: \", len(list_files))\n",
        "  fail_process = 0\n",
        "  cnt_predict = 0\n",
        "\n",
        "  start_time = time.time()\n",
        "  for filename in list_files:\n",
        "    img = cv2.imread(os.path.join(input_folder, filename))\n",
        "    print(filename, img.shape, end = \" \")\n",
        "    try:\n",
        "      label = model.find_label(img)\n",
        "    except:\n",
        "      label = -1\n",
        "\n",
        "    if img_to_label[filename] == label:\n",
        "      cnt_predict += 1\n",
        "    elif label == -1:\n",
        "      print(filename)\n",
        "      fail_process += 1\n",
        "\n",
        "  run_time = time.time() - start_time\n",
        "\n",
        "  print(\"Ket qua dung: %i/%i\" % (cnt_predict, len(list_files)))\n",
        "  print(\"Loi: %i\" % fail_process)\n",
        "  print(\"Score = %.2f\" % (10.*cnt_predict/len(list_files)))\n",
        "  print(\"Run time in: %.2f s\" % run_time)\n",
        "  cv2.waitKey(0)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/archive/v0.10.0.zip\" to /root/.cache/torch/hub/v0.10.0.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run time in: 1.62 s\n",
            "Total test images:  10\n",
            "img10.jpeg (1024, 1024, 3) tensor([[-11.2745,  18.5592,  -6.0317,  -1.1337]]) others\n",
            "img2.jpeg (966, 800, 3) tensor([[ 6.2059, -5.0238, -2.1173,  0.6191]]) highlands\n",
            "img7.jpeg (768, 1024, 3) tensor([[-9.1351,  8.7940, -0.1771,  0.5555]]) others\n",
            "img6.jpeg (966, 800, 3) tensor([[-10.0128,  -2.0488,  -1.7373,  12.8300]]) starbucks\n",
            "img4.jpeg (1067, 800, 3) tensor([[-8.5241, -1.8575,  8.5299,  1.6615]]) phuclong\n",
            "img9.jpeg (931, 1242, 3) tensor([[-17.3158,  20.0756,  -1.6189,  -1.0640]]) others\n",
            "img5.jpeg (966, 800, 3) tensor([[-6.0900, -2.9504, 10.3984, -1.3515]]) phuclong\n",
            "img8.jpeg (701, 526, 3) tensor([[-0.8500,  0.0864,  0.1131,  0.5032]]) starbucks\n",
            "img1.jpeg (1067, 800, 3) tensor([[ 8.6434, -3.0901, -1.7657, -4.0277]]) highlands\n",
            "img3.jpeg (1067, 800, 3) tensor([[ 8.6434, -3.0901, -1.7657, -4.0277]]) highlands\n",
            "Ket qua dung: 9/10\n",
            "Loi: 0\n",
            "Score = 9.00\n",
            "Run time in: 1.27 s\n"
          ]
        }
      ]
    }
  ]
}