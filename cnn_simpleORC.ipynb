{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn-simpleORC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NguyenThuan215/int3404-3-simpleORC/blob/main/cnn_simpleORC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbCZ0eDhwFGc"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from collections import namedtuple\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDGyxi9BwXhf",
        "outputId": "a361f2dd-bf9c-461b-91b0-e138432ef7df"
      },
      "source": [
        "!git clone https://github.com/NguyenThuan215/int3404-3-simpleORC/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'int3404-3-simpleORC'...\n",
            "remote: Enumerating objects: 671, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 671 (delta 1), reused 21 (delta 1), pack-reused 649\u001b[K\n",
            "Receiving objects: 100% (671/671), 654.80 MiB | 31.80 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "Checking out files: 100% (637/637), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPy66u7owkjk"
      },
      "source": [
        "traindir = \"/content/int3404-3-simpleORC/data/train\"\n",
        "testdir = \"/content/int3404-3-simpleORC/data/test\"\n",
        "modeldir = \"/content/int3404-3-simpleORC/model.pth\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hky6bxmVxOMM"
      },
      "source": [
        "transform_train = transforms.Compose([\n",
        "                                  transforms.Resize((256,256)),\n",
        "                                  transforms.RandomCrop(224, padding=4),\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                  ])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "                                  transforms.Resize((224,224)),\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                  ])\n",
        "\n",
        "TrainTest = namedtuple('TrainTest', ['train', 'test'])\n",
        "classes = ['highlands', 'others', 'phuclong', 'starbucks']\n",
        "def prepare_data():\n",
        "  trainset = torchvision.datasets.ImageFolder(root=traindir, transform=transform_train)\n",
        "  testset = torchvision.datasets.ImageFolder(root=testdir, transform=transform_test)\n",
        "  return TrainTest(train=trainset, test=testset)\n",
        "\n",
        "def prepare_loader(datasets):\n",
        "  batch = 8\n",
        "  worker = 4\n",
        "  trainloader = DataLoader(dataset=datasets.train, batch_size=batch, shuffle=True, num_workers=worker)\n",
        "  testloader = DataLoader(dataset=datasets.test, batch_size=batch, shuffle=False, num_workers=worker)\n",
        "  return TrainTest(train=trainloader, test=testloader)\n",
        "  \n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5 \n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TbhWa2m291C"
      },
      "source": [
        "def train_epoch(epoch, model, loader, loss_func, optimizer, device):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  final_loss = 0.0\n",
        "  reporting_steps = 10\n",
        "  step = 0\n",
        "  for images, labels in loader:\n",
        "    step += 1\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = model(images)\n",
        "    loss = loss_func(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    final_loss = loss.item()\n",
        "    running_loss += final_loss\n",
        "    if step % reporting_steps == reporting_steps - 1:\n",
        "      print(f\"Epoch {epoch} step {step} ave_loss {running_loss/reporting_steps:.4f}\")\n",
        "      running_loss = 0.0\n",
        "  return final_loss\n",
        "\n",
        "def test_epoch(epoch, model, loader, device):\n",
        "  ytrue = []\n",
        "  ypred = []\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    for images, labels in loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs, dim=1)\n",
        "      ytrue += list(labels.cpu().numpy())\n",
        "      ypred += list(predicted.cpu().numpy())\n",
        "\n",
        "  return ypred, ytrue"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC6y0Ufc3G2F"
      },
      "source": [
        "def main():\n",
        "  PATH = \"./model.pth\"\n",
        "  class_out = len(classes)\n",
        "\n",
        "  datasets = prepare_data()\n",
        "  loaders = prepare_loader(datasets)\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  print(\"image size: \", datasets.test[0][0].shape)\n",
        "  print(\"len train: \", len(datasets.train))\n",
        "  print(\"len test: \", len(datasets.test))\n",
        "  print(\"len batch train: \", len(loaders.train))\n",
        "  print(\"device:\", device)\n",
        "\n",
        "  model = torchvision.models.resnet18(pretrained=True)\n",
        "  model.fc = torch.nn.modules.linear.Linear(in_features=512, out_features=class_out, bias=True)\n",
        "  model.to(device)\n",
        "\n",
        "  loss_func = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "  accuracies = []\n",
        "  losses = []\n",
        "  for epoch in range(40):\n",
        "    print(\"---------------------------------------------------------------\")\n",
        "    loss = train_epoch(epoch, model, loaders.train, loss_func, optimizer, device)\n",
        "    ypred_test, ytrue_test = test_epoch(epoch, model, loaders.test, device)\n",
        "\n",
        "    print(classification_report(ytrue_test, ypred_test, target_names=classes))\n",
        "    torch.save(model.state_dict(), PATH)\n",
        "\n",
        "    # calculate report\n",
        "    ypred_test = np.array(ypred_test)\n",
        "    ytrue_test = np.array(ytrue_test)\n",
        "    accuracy = int((ytrue_test==ypred_test).sum() / len(ytrue_test) *100)\n",
        "    accuracies.append(accuracy)\n",
        "    losses.append(round(loss, 4))\n",
        "\n",
        "  print(\"accr: \", accuracies)\n",
        "  print(\"loss: \", losses)\n",
        "  return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Psnd0q-2zrTd"
      },
      "source": [
        "datasets = prepare_data()\n",
        "loader = prepare_loader(datasets)\n",
        "imshow(datasets.test[21][0])\n",
        "print(datasets.test[21][1])\n",
        "print(\"class:\", datasets.train.classes)\n",
        "model = main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEUvylX02M39",
        "outputId": "011334a9-15a6-405c-b9f0-494fe7f8b55f"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "modeldir = \"/content/int3404-3-simpleORC/model.pth\"\n",
        "sample_dir = '/content/int3404-3-simpleORC/sampledata'\n",
        "\n",
        "#load model\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "model.fc = torch.nn.modules.linear.Linear(in_features=512, out_features=4, bias=True)\n",
        "model.to(device)\n",
        "model.load_state_dict(torch.load(modeldir, map_location=device))\n",
        "model.to(device)\n",
        "\n",
        "#transforms\n",
        "img_transforms = transforms.Compose([\n",
        "                                transforms.Resize((224,224)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                ])\n",
        "\n",
        "images = os.listdir(sample_dir) #list of image\n",
        "images.sort()\n",
        "\n",
        "ypred = []\n",
        "for image_name in images:\n",
        "  path = os.path.join(sample_dir, image_name)\n",
        "  image = Image.open(path)\n",
        "  image = img_transforms(image)\n",
        "  image = np.transpose(image, (0,1,2))\n",
        "  image = image.unsqueeze(0) \n",
        "  image = image.to(device)\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "     output = model(image)\n",
        "     _, predicted = torch.max(output, dim=1)\n",
        "     ypred += (list(predicted.cpu().numpy()))\n",
        "     print(image_name, output, classes[int(predicted.cpu().numpy())])\n",
        "\n",
        "print(ypred)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img1.jpeg tensor([[11.1119, -4.3118, -2.9040, -4.1733]], device='cuda:0') highlands\n",
            "img10.jpeg tensor([[-6.7432, 14.7271, -6.5645, -1.3590]], device='cuda:0') others\n",
            "img2.jpeg tensor([[ 6.4072, -4.8636, -1.9358,  0.0890]], device='cuda:0') highlands\n",
            "img3.jpeg tensor([[11.1119, -4.3118, -2.9040, -4.1733]], device='cuda:0') highlands\n",
            "img4.jpeg tensor([[-6.9463, -2.6218,  8.9481,  0.4895]], device='cuda:0') phuclong\n",
            "img5.jpeg tensor([[-3.6445, -5.3688, 11.0620, -2.0510]], device='cuda:0') phuclong\n",
            "img6.jpeg tensor([[-9.8279, -3.4960, -4.1228, 16.4280]], device='cuda:0') starbucks\n",
            "img7.jpeg tensor([[-2.8155,  2.4542, -0.6047,  0.8546]], device='cuda:0') others\n",
            "img8.jpeg tensor([[-0.5924, -0.1753, -0.2259,  0.8041]], device='cuda:0') starbucks\n",
            "img9.jpeg tensor([[-6.4125, 13.2863, -2.9095, -4.0267]], device='cuda:0') others\n",
            "[0, 1, 0, 0, 2, 2, 3, 1, 3, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH5z7QZ99BRV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}